\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces Decision regions for classical inference for $H_0: \mu =\mu _0$ vs $H_a:\mu >\mu _0$.}}{4}{figure.12}
\contentsline {figure}{\numberline {1.2}{\ignorespaces A typical lineup plot ($m = 20$) for testing $H_0: \mu _1 = \mu _2$. When the alternative hypothesis is true the observed plot should have the largest vertical difference between the centers. Can you identify the observed plot?}}{7}{figure.15}
\contentsline {figure}{\numberline {1.3}{\ignorespaces Sampling distribution of the test statistic with the observed value and the values for the null plots corresponding to the lineup in Figure \ref {lineup}.}}{8}{figure.17}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces LD1 versus LD2 from an LDA on a randomly selected subset of 40 significantly different oligos : F, Foundress; G, gyne; Q, queen and W, worker. It can be noticed that the groups F and G are separated. This plot is generated to match Figure 2 in \cite {toth:2010}. }}{15}{figure.23}
\contentsline {figure}{\numberline {2.2}{\ignorespaces A typical lineup ($m = 20$) for testing $H_o: \mu _1 = \mu _2$. When the alternative hypothesis is true, the observed data plot should have the largest vertical difference between the centers. Can you identify the observed data plot? The solution to the lineup is provided in the Appendix.}}{20}{figure.26}
\contentsline {figure}{\numberline {2.3}{\ignorespaces Lineup of the wasps data. One plot shows the observed data and the remaining 19 show null data where the wasp type labels were randomly assigned. Each plot was produced by conducting LDA on the 40D data to produce the 2D projection with best separation. Which plot shows the most separation between the 4 groups? The solution is provided in the Appendix.}}{23}{figure.34}
\contentsline {figure}{\numberline {2.4}{\ignorespaces Plots showing example 1D projections for $p=2, 8, 15, 22, 28$ and $n = 30$ for purely noise data. The probability of obtaining a projection where groups are separated is calculated and displayed below the plots. Of course, once a projection is computed the groups are either separated or not - the event occurred or didn't - and we can see that the last two plots display separated groups. The difference between the groups increases as $p$ increases, and the likelihood of obtaining a projection with separation increases.}}{25}{figure.41}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {P(sep$|n,2$) = 0.00}}}{25}{figure.41}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {P(sep$|n,8$) = 0.01}}}{25}{figure.41}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {P(sep$|n,15$) = 0.64}}}{25}{figure.41}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {P(sep$|n,22$) = 0.99}}}{25}{figure.41}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {P(sep$|n,28$) = 1.00}}}{25}{figure.41}
\contentsline {figure}{\numberline {2.5}{\ignorespaces The visual test statistics $V_1({\unhbox \voidb@x \hbox {\relax \mathversion {bold}{\bf Y}}})$ and $V_2({\unhbox \voidb@x \hbox {\relax \mathversion {bold}{\bf Y}}})$ used. $V_1({\unhbox \voidb@x \hbox {\relax \mathversion {bold}{\bf Y}}})$ is a horizontal jittered dot plot while $V_2({\unhbox \voidb@x \hbox {\relax \mathversion {bold}{\bf Y}}})$ is a scatterplot of the first and second dimensional projections, with color representing groups in both cases. }}{28}{figure.49}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {$V_1({\unhbox \voidb@x \hbox {\relax \mathversion {bold}{\bf Y}}})$}}}{28}{figure.49}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {$V_2({\unhbox \voidb@x \hbox {\relax \mathversion {bold}{\bf Y}}})$}}}{28}{figure.49}
\contentsline {figure}{\numberline {2.6}{\ignorespaces Lineup ($m=20$) from treatment with $p = 20$, separation = Yes and $d = 1$. The subjects were asked to identify the plot with the most separated colors. Can you identify the observed data plot? The solution to the lineup is provided in the Appendix. }}{29}{figure.50}
\contentsline {figure}{\numberline {2.7}{\ignorespaces Lineup ($m=20$) from treatment with $p = 100$, separation = No and $d = 2$.The subjects were asked to identify the plot with the most separation between the colored groups. Can you identify the observed data plot? The solution is provided in the Appendix. }}{30}{figure.51}
\contentsline {figure}{\numberline {2.8}{\ignorespaces Detection rate by dimension, faceted by projection and separation. The three points represents the three replicates for each treatment level. A fixed effects logistic regression model is overlaid on the points. It can be seen that the detection rate decreases as $p$ increases for data with real separation. When the data is purely noise data, the detection rate is flat across dimensions. Detection rate does not change with projection. Even with $p = 100$ subjects more often detected separation than would be expected by chance. }}{32}{figure.55}
\contentsline {figure}{\numberline {2.9}{\ignorespaces Time taken in seconds to respond on log scale against dimension colored by separation and faceted by projection. A line shows the trend over dimension for each separation within projection. Bootstrap resampling bands are drawn for each colored lines. Time taken to respond is higher when the data has no separation. Also as dimension increases, the time to answer when there is separation is equal to the time taken when there is no separation. }}{34}{figure.58}
\contentsline {figure}{\numberline {2.10}{\ignorespaces Comparing the choices that subjects make for each lineup. Relative frequency of plots chosen against a measure of the average separation between groups, the larger the value the more separated are the groups. Each cell here shows the data for one of the lineups used in the experiment, 60 in total, and each ``pin'' represents a plot in the lineup, 20 for each lineup. Red indicates the observed data plot. Subjects are asked to pick the plot in the lineup where the groups are the most separated, so we would expect that more subjects would pick the plots with the largest average separation. In general, this happens, the tallest pins are in the right of each cell. The top three rows show the results for the data with separation, so the observed data plot (red) is typically the pin on the very left of the cell, less so for the higher dimensions which are the cells at right. Figure (a) shows 1D projections and Figure (b) shows for 2D projections. There is not much difference between the two figures. }}{35}{figure.62}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Projection:1D}}}{35}{figure.62}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Projection:2D}}}{35}{figure.62}
\contentsline {figure}{\numberline {2.11}{\ignorespaces Detection rate and mean time taken to respond in seconds are plotted against the difference for 1D and 2D projections separately. The difference is between maximum separation of all the null plots and separation of the observed data plot for each lineup for 1D projections but for 2D projections the difference is based on the average separation between the groups. The vertical line represents difference equal to 1 when the average separation of the observed data plot is equal to the maximum average separation of the null plots for 2D projection. The points left to the line indicates a difficult lineup in the sense that at least one of the null plots had a lower average separation value than the observed data plot. (a) and (b) As difference increases, detection rate increases. (c) and (d) As difference increases, mean time taken decreases indicating that the subjects have an easier time in identifying the observed data plot. }}{37}{figure.68}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Projection:1D}}}{37}{figure.68}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Projection:2D}}}{37}{figure.68}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Projection:1D}}}{37}{figure.68}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {Projection:2D}}}{37}{figure.68}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Lineup plot of size $m = 20$ using scatterplots with regression line overlaid. This tests $H_o: \beta _k = 0$, where covariate $X_k$ is continuous. One of the plots in the lineup is the plot of the true data. The other plots are null plots generated by simulating data from a null model that assumes that the null hypothesis is true. Can you identify the plot with the steepest slope? }}{42}{figure.74}
\contentsline {figure}{\numberline {3.2}{\ignorespaces If the lineup protocol was to be used instead of classical inference this is what it would look like. (a) Decision region (shaded in red) for classical inference for $H_0: \mu =\mu _0$ vs $H_a:\mu >\mu _0$ and (b) values corresponding to the true value (red) and the null plots (blue) in a single lineup of size $m=20$ that would be used to test the same null hypothesis. The actual data plot is extreme relative to the null plots, and observers would likely be able to pick it out, resulting in a decision to reject the null hypothesis. In practice, the lineup protocol would not be used if a classical test can be used.}}{43}{figure.77}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Classical Inference}}}{43}{figure.77}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Visual Inference}}}{43}{figure.77}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Illustration of binned distance, for data with strong association (a), and the same data where one variable has been permuted (b). The scatterplot of the data is shown (left) along with the binned view of the data (center) and the number of points in each cell (right). Binned distance is the euclidean distance of these counts. The binned distance between these plots is 6.4807. }}{48}{figure.84}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces { Dataset $X$ with two variables $X_1$ and $X_2$}}}{48}{figure.84}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces { Dataset $Y$ with permuted $X_1$ and original $X_2$}}}{48}{figure.84}
\contentsline {figure}{\numberline {3.4}{\ignorespaces Illustration of three different distance metrics based on separation. Two dimensional projections are plotted with 3 groups. Minimum Separation (in (a)) calculates the minimum distance between points of each cluster from the other clusters. Average separation (in (b)) calculates the average distance of each point in a cluster to the other clusters. In (c), the cluster mean distance calculates the distance between the means of each cluster. }}{51}{figure.88}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {Minimum Separation}}}{51}{figure.88}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {Average Separation}}}{51}{figure.88}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {Cluster Mean Separation}}}{51}{figure.88}
\contentsline {figure}{\numberline {3.5}{\ignorespaces Optional caption for list of figures}}{53}{figure.96}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{53}{figure.96}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{53}{figure.96}
\contentsline {figure}{\numberline {3.6}{\ignorespaces Optional caption for list of figures}}{54}{figure.99}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{54}{figure.99}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{54}{figure.99}
\contentsline {figure}{\numberline {3.7}{\ignorespaces Optional caption for list of figures}}{56}{figure.103}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{56}{figure.103}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{56}{figure.103}
\contentsline {figure}{\numberline {3.8}{\ignorespaces An example lineup from Turk Experiment 1. The lineup has $m = 20$ plots of which one is the observed data plot and the remaining $m - 1$ are the null plots generated assuming that the null hypothesis is true. Subjects were asked to identify the plot which has the largest vertical difference between the two groups. Can you identify the observed data plot?}}{59}{figure.110}
\contentsline {figure}{\numberline {3.9}{\ignorespaces Optional caption for list of figures}}{60}{figure.113}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{60}{figure.113}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{60}{figure.113}
\contentsline {figure}{\numberline {3.10}{\ignorespaces Optional caption for list of figures}}{61}{figure.114}
\contentsline {figure}{\numberline {3.11}{\ignorespaces Optional caption for list of figures}}{62}{figure.119}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{62}{figure.119}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{62}{figure.119}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{62}{figure.119}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{62}{figure.119}
\contentsline {figure}{\numberline {3.12}{\ignorespaces An example lineup from Turk Experiment 2. In this lineup, one of the plots is the observed plot and the other 19 plots are the null plots generated assuming that the null hypothesis $H_o : \beta = 0$ is true. Subjects were asked to identify the plot with the steepest slope. Can you identify the observed plot ?}}{64}{figure.121}
\contentsline {figure}{\numberline {3.13}{\ignorespaces Optional caption for list of figures}}{65}{figure.124}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{65}{figure.124}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{65}{figure.124}
\contentsline {figure}{\numberline {3.14}{\ignorespaces Optional caption for list of figures}}{66}{figure.125}
\contentsline {figure}{\numberline {3.15}{\ignorespaces Optional caption for list of figures}}{68}{figure.132}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{68}{figure.132}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{68}{figure.132}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{68}{figure.132}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{68}{figure.132}
\contentsline {subfigure}{\numberline {(e)}{\ignorespaces {}}}{68}{figure.132}
\contentsline {subfigure}{\numberline {(f)}{\ignorespaces {}}}{68}{figure.132}
\contentsline {figure}{\numberline {3.16}{\ignorespaces An example lineup from Turk Experiment 7. Here two dimensional projections of the PDA index are plotted for a data with separation having $p = 20$ dimensions and $n = 30$ observations. The subjects were asked to identify the plot with the most separated colors. Can you identify the observed data plot?}}{69}{figure.134}
\contentsline {figure}{\numberline {3.17}{\ignorespaces Optional caption for list of figures}}{70}{figure.137}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{70}{figure.137}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{70}{figure.137}
\contentsline {figure}{\numberline {3.18}{\ignorespaces Optional caption for list of figures}}{71}{figure.138}
\contentsline {figure}{\numberline {3.19}{\ignorespaces Optional caption for list of figures}}{72}{figure.143}
\contentsline {subfigure}{\numberline {(a)}{\ignorespaces {}}}{72}{figure.143}
\contentsline {subfigure}{\numberline {(b)}{\ignorespaces {}}}{72}{figure.143}
\contentsline {subfigure}{\numberline {(c)}{\ignorespaces {}}}{72}{figure.143}
\contentsline {subfigure}{\numberline {(d)}{\ignorespaces {}}}{72}{figure.143}
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces A typical lineup. The plot of the actual data is embedded in a set of null plots which are generated assuming that the null hypothesis is true. The variable ``mpg'' is permuted 19 times to obtain the 19 null plots. Can you identify the plot which has the steepest slope? The true position of the plot can be obtain by copying and pasting ``decrypt(...)'' from the output into R console.}}{82}{figure.155}
\contentsline {figure}{\numberline {4.2}{\ignorespaces Illustration of the Rorschach protocol. These nine scatterplots are obtained by permuting the variable ``mpg'' while keeping the variable ``wt'' fixed. Does it look like the strength of the relationship is same in all the plots? Is there a plot which has more interesting pattern than others? }}{84}{figure.157}
\contentsline {figure}{\numberline {4.3}{\ignorespaces Lineup plot of size $m = 20$ of scatterplots between ``mpg'' and ``wt'' with a regression line overlaid. The plot of the actual data is randomly placed among the set of null plots. The position of the plot of the actual data is 10. }}{88}{figure.166}
\contentsline {figure}{\numberline {4.4}{\ignorespaces Illustration of the optimum bin selection procedure. The obtained lineup data from subsection \ref {calculating-the-mean-distances-for-the-plots-in-the-lineup} is used to generate difference between the true plot and the maximum of the null plots using a binned distance for all combinations of number of bins on both x and y axes. The number of bins on x and y axes are plotted on x and y respectively with the colors showing the differences. The darker color represents larger difference. }}{91}{figure.169}
\contentsline {figure}{\numberline {4.5}{\ignorespaces Distribution of the \textbf {regression based distance} with the distance for the null plots of the lineup represented in black and the distance for the plot of the actual data represented by orange. The distance for the actual plot is much higher than the null plots and the actual plot can be easily identified as seen in Figure \ref {lineup-reg}. }}{94}{figure.173}
\contentsline {figure}{\numberline {4.6}{\ignorespaces Distribution of the \textbf {binned distance} with the distance for the null plots of the lineup represented in black and the distance for the plot of the actual data represented by orange. The number of bins used is 6 on both axes. The distance for the actual plot falls within the distances for the null plots. This shows that the lineup is difficult in the sense that the actual cannot be easily identified. Hence the selection of the number of bins is important for binned distance. }}{95}{figure.174}
\contentsline {figure}{\numberline {4.7}{\ignorespaces Distribution of the \textbf {binned distance} with the distance for the null plots of the lineup represented in black and the distance for the plot of the actual data represented by orange. The number of bins used is 3 on x-axis and 2 on y-axis. The number of bins are selected by the optimal bin selection method using Figure \ref {opt-bin}. The distance for the actual plot is larger than the distances for the null plots which matches the lineup.}}{96}{figure.175}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Plot showing the distribution of the sum of absolute difference of means for data with and without separation for different dimensions. The distributions of data with real separation (V) and purely noise data (U) are shown in brown and green respectively with the dark purple line showing the 5th percentile of V. The dark purple area shows the area of U which is greater than the 5th percentile of V. The dark purple region ($\delta $) increases as dimension ($p$) increases. }}{102}{figure.184}
